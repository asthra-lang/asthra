{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ðŸš€ Asthra LLM Fine-Tuning on Google Colab\n",
        "\n",
        "This notebook trains a fine-tuned language model for the Asthra programming language using Google Colab's free/Pro GPUs.\n",
        "\n",
        "## ðŸ“‹ Before You Start\n",
        "\n",
        "1. **Enable GPU**: Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU (preferably A100)\n",
        "2. **Colab Pro Recommended**: For A100 access and longer runtimes\n",
        "3. **Expected Time**: 2-4 hours for cloud-optimized config\n",
        "4. **Expected Cost**: $10/month for Colab Pro\n",
        "\n",
        "## ðŸŽ¯ What This Does\n",
        "\n",
        "- Trains a Gemma-2-2B model on Asthra programming language\n",
        "- Uses efficient LoRA fine-tuning for fast training\n",
        "- Optimized for cloud GPUs and cost efficiency\n",
        "- Produces a model compatible with OpenAI API servers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ”§ Setup Environment\n",
        "print(\"ðŸš€ Setting up Asthra LLM training environment...\")\n",
        "\n",
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "# Install required packages\n",
        "%pip install torch transformers datasets accelerate trl peft tokenizers\n",
        "%pip install tensorboard wandb  # Optional monitoring\n",
        "\n",
        "print(\"âœ… Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“¥ Clone Asthra Repository\n",
        "print(\"ðŸ“¥ Cloning Asthra repository...\")\n",
        "\n",
        "# Clone the repository (replace with your repo URL)\n",
        "!git clone https://github.com/your-username/asthra-lang.git\n",
        "%cd asthra-lang/llmfinetuning\n",
        "\n",
        "# List available configurations\n",
        "print(\"\\nðŸ“‹ Available training configurations:\")\n",
        "!ls -la configs/*.yaml\n",
        "\n",
        "print(\"âœ… Repository cloned successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
