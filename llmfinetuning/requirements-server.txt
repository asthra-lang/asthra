# OpenAI-Compatible Server Requirements
# Core dependencies for running Asthra model servers

# FastAPI server dependencies
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.5.0

# Core ML framework  
torch>=2.3.0
transformers>=4.46.0
accelerate>=0.34.0
tokenizers>=0.20.0

# Mistral/Devstral specific
mistral-common>=1.5.5

# vLLM server (Linux/CUDA only - comment out on macOS)
# vllm>=0.8.5

# Basic utilities
numpy>=1.26.0
pyyaml>=6.0.1
python-dotenv>=1.0.0
psutil>=5.9.8

# OpenAI client for testing
openai>=1.12.0
httpx>=0.25.0
requests>=2.31.0

# Development and testing
pytest>=8.0.0
pytest-asyncio>=0.21.0
aiofiles>=23.0.0
websockets>=12.0.0

# Rich output for CLI
rich>=13.7.0
click>=8.1.7

# Optional: For GGUF/Ollama integration
# llama-cpp-python>=0.2.88
# gguf>=0.9.1

# Security
cryptography>=41.0.0 