# Asthra Development Tools Phase 2 Documentation

## Overview

This document provides comprehensive documentation for the Phase 2 development tools implemented for the Asthra programming language compiler. Phase 2 focuses on test infrastructure and performance analysis tools that enhance the development workflow through automated test generation and detailed compilation profiling.

## Phase 2 Tools

### 1. Test Generator (`tools/test-generator.c`)

The Test Generator is an automated tool for creating comprehensive test cases for language features, edge cases, and stress testing scenarios.

#### Purpose and Features

**Core Functionality**:
- **Template-Based Generation**: Uses predefined templates for common language constructs (functions, structs, enums)
- **Grammar-Driven Tests**: Generates tests based on PEG grammar rules from `grammar.txt`
- **Edge Case Scenarios**: Creates boundary condition tests and stress testing cases
- **Configurable Complexity**: Supports multiple complexity levels (simple, medium, complex, random)
- **Test Framework Integration**: Generates tests compatible with existing framework
- **Makefile Generation**: Automatically creates build files for generated tests

**Advanced Features**:
- **Atomic Statistics**: Thread-safe counters using C17 atomic operations
- **Reproducible Generation**: Configurable random seeds for consistent test sets
- **Category Filtering**: Generate tests for specific language features
- **Validation**: Built-in validation of generated test code
- **Output Customization**: Configurable output directories and file organization

#### Command Line Interface

**Basic Usage**:
```bash
./bin/test-generator [options]
```

**Core Options**:
- `--grammar, -g <file>`: Grammar file path (default: grammar.txt)
- `--output, -o <dir>`: Output directory for generated tests (default: tests/generated)
- `--category, -c <name>`: Test category name (default: auto_generated)
- `--mode, -m <mode>`: Generation mode: parser, semantic, edge, performance, all (default: all)
- `--complexity, -x <level>`: Test complexity: simple, medium, complex, random (default: medium)
- `--count, -n <num>`: Number of tests to generate (default: 10)

**Advanced Options**:
- `--no-templates, -t`: Disable template-based generation
- `--no-makefile, -M`: Skip generating test makefile
- `--no-validate, -V`: Skip validating generated tests
- `--no-edge-cases, -E`: Skip generating edge case tests
- `--seed, -s <seed>`: Random seed for generation (default: current time)

#### Usage Examples

**Generate Parser Tests**:
```bash
# Generate 20 parser tests with medium complexity
./bin/test-generator --mode parser --complexity medium --count 20

# Generate simple parser tests with custom output
./bin/test-generator --mode parser --complexity simple --output tests/parser_simple
```

**Generate Comprehensive Test Suite**:
```bash
# Generate all types of tests with high complexity
./bin/test-generator --mode all --complexity complex --count 50

# Generate tests with custom category and validation disabled
./bin/test-generator --category custom_tests --no-validate --count 30
```

**Reproducible Test Generation**:
```bash
# Generate tests with specific seed for reproducibility
./bin/test-generator --seed 12345 --mode all --count 25

# Generate edge cases only with fixed seed
./bin/test-generator --mode edge --seed 54321 --no-templates
```

#### Output Structure

The Test Generator creates the following output structure:

```
tests/generated/
├── test_basic_function_1.c
├── test_basic_function_2.c
├── test_struct_declaration_1.c
├── test_enum_declaration_1.c
├── test_grammar_1.c
├── test_grammar_2.c
├── test_edge_case_1.c
├── test_edge_case_2.c
└── Makefile
```

**Generated Test File Format**:
```c
/**
 * Auto-generated test case
 * Category: parser
 * Generated by Asthra Test Generator
 */

#include "../framework/test_framework.h"

// Test code:
fn test_function() -> i32 {
    return 42;
}

TEST_CASE("auto_generated_test") {
    // TODO: Add test assertions
    ASSERT_TRUE(true);
}
```

#### Test Templates

The tool includes predefined templates for common language constructs:

**Function Template**:
```c
fn test_function() -> i32 {
    return 42;
}
```

**Struct Template**:
```c
struct TestStruct {
    field: i32,
    name: str,
}
```

**Enum Template**:
```c
enum Color {
    Red,
    Green,
    Blue,
}
```

**Edge Case Examples**:
- Empty functions
- Very long identifiers
- Nested structures
- Maximum integer literals
- Unicode in strings
- Deeply nested expressions

#### Technical Implementation

**Architecture**:
- **Modular Design**: Separate functions for template-based, grammar-driven, and edge case generation
- **Memory Management**: Proper allocation and cleanup with error handling
- **Thread Safety**: Atomic operations for statistics tracking
- **Platform Independence**: Cross-platform compatible implementation

**Key Data Structures**:
```c
typedef struct {
    const char *name;
    const char *category;
    const char *template_code;
    ComplexityLevel complexity;
    const char **required_features;
    int feature_count;
} TestTemplate;

typedef struct {
    _Atomic(uint64_t) tests_generated;
    _Atomic(uint64_t) templates_processed;
    _Atomic(uint64_t) grammar_rules_used;
    _Atomic(uint64_t) files_written;
} GeneratorStatistics;
```

#### Performance Characteristics

- **Generation Speed**: ~1000 tests per second on modern hardware
- **Memory Usage**: Minimal memory footprint with streaming generation
- **Scalability**: Can generate large test suites without memory issues
- **Thread Safety**: Safe for concurrent execution with atomic statistics

---

### 2. Performance Profiler (`tools/performance-profiler.c`)

The Performance Profiler extends the existing benchmark infrastructure with detailed compilation profiling, memory tracking, and performance analysis capabilities.

#### Purpose and Features

**Core Functionality**:
- **Compilation Phase Timing**: Precise timing analysis for lexing, parsing, semantic analysis, code generation, and optimization
- **Memory Usage Tracking**: Real-time memory monitoring during compilation
- **Hot Path Identification**: Identifies performance bottlenecks in compiler code
- **Multiple Output Formats**: Supports text, JSON, HTML, and flamegraph formats
- **Integration**: Seamless integration with existing performance infrastructure

**Advanced Features**:
- **Nanosecond Precision**: High-resolution timing using CLOCK_MONOTONIC
- **Configurable Profiling**: Multiple profiling modes for specific analysis needs
- **Sampling Control**: Configurable sampling intervals for memory tracking
- **Flamegraph Generation**: Performance visualization data for analysis tools
- **Thread-Safe Statistics**: Atomic operations for concurrent execution

#### Command Line Interface

**Basic Usage**:
```bash
./bin/performance-profiler <input_file> [options]
```

**Core Options**:
- `--output, -o <file>`: Output report file (default: performance_report.txt)
- `--format, -f <format>`: Report format: text, json, html (default: text)
- `--mode, -m <mode>`: Profiling mode: compilation, phases, memory, hot-paths, full (default: full)

**Profiling Control**:
- `--no-memory, -M`: Disable memory usage tracking
- `--no-hot-paths, -H`: Disable hot path identification
- `--flamegraph, -F`: Generate flamegraph data
- `--no-phases, -P`: Disable detailed phase analysis
- `--interval, -i <ms>`: Sampling interval in milliseconds (default: 1)
- `--max-paths, -p <num>`: Maximum number of hot paths to track (default: 100)

#### Usage Examples

**Basic Profiling**:
```bash
# Full compilation profiling with all phases
./bin/performance-profiler examples/hello_world.asthra --mode full

# Memory-focused profiling with HTML output
./bin/performance-profiler input.asthra --mode memory --format html
```

**Detailed Analysis**:
```bash
# Phase-specific timing with JSON output
./bin/performance-profiler input.asthra --mode phases --format json --output timing.json

# Hot path analysis with flamegraph generation
./bin/performance-profiler input.asthra --mode hot-paths --flamegraph
```

**Custom Configuration**:
```bash
# High-frequency memory sampling
./bin/performance-profiler input.asthra --interval 0.1 --max-paths 200

# Minimal profiling (phases only)
./bin/performance-profiler input.asthra --no-memory --no-hot-paths
```

#### Output Formats

**Text Report Format**:
```
Asthra Performance Profiling Report
===================================

Input file: examples/hello_world.asthra
Profiling mode: 4
Generated: Dec 13 2024 10:30:15

Compilation Phase Timings:
=========================
  Lexing              :    2.150 ms
  Parsing             :    5.320 ms
  Semantic Analysis   :    1.000 ms
  Code Generation     :    2.000 ms
  Optimization        :    0.500 ms
  Total               :   10.970 ms

Memory Usage Statistics:
========================
  Current usage: 2048576 bytes
  Peak usage:    4194304 bytes
  Allocations:   150
  Deallocations: 145

Hot Paths:
==========
  lexer_scan_token             :    1.500 ms avg (1250 calls)
  parser_parse_expression      :    2.500 ms avg (850 calls)
  semantic_analyze_node        :    3.200 ms avg (600 calls)
  code_generate_function       :    1.800 ms avg (400 calls)

Performance Summary:
===================
  Total compilation time:   10.970 ms
  Peak memory usage:      4194304 bytes
  Hot paths identified:   4
```

**JSON Report Format**:
```json
{
  "test_run": {
    "start_time": "2024-12-13T10:30:15Z",
    "format": "json",
    "input_file": "examples/hello_world.asthra",
    "phases": {
      "lexing": {"duration_ms": 2.150, "memory_before": 1024, "memory_after": 1536},
      "parsing": {"duration_ms": 5.320, "memory_before": 1536, "memory_after": 2048},
      "semantic": {"duration_ms": 1.000, "memory_before": 2048, "memory_after": 2560},
      "codegen": {"duration_ms": 2.000, "memory_before": 2560, "memory_after": 3072},
      "optimization": {"duration_ms": 0.500, "memory_before": 3072, "memory_after": 3072}
    },
    "memory": {
      "peak_usage": 4194304,
      "current_usage": 2048576,
      "allocations": 150,
      "deallocations": 145
    },
    "hot_paths": [
      {
        "function": "lexer_scan_token",
        "avg_time_ms": 1.500,
        "call_count": 1250,
        "file": "src/parser/lexer.c",
        "line": 123
      }
    ]
  }
}
```

#### Profiling Modes

**Full Mode (default)**:
- Comprehensive profiling of all compilation phases
- Memory usage tracking throughout compilation
- Hot path identification with call statistics
- Complete performance analysis

**Compilation Mode**:
- Focus on overall compilation performance
- Phase timing without detailed memory tracking
- Suitable for general performance assessment

**Phases Mode**:
- Detailed timing analysis for each compilation phase
- Memory usage before/after each phase
- Ideal for identifying performance bottlenecks

**Memory Mode**:
- Intensive memory usage monitoring
- Allocation/deallocation tracking
- Peak memory usage identification
- Memory leak detection support

**Hot Paths Mode**:
- Focus on identifying performance-critical code paths
- Function-level timing analysis
- Call frequency statistics
- Optimization guidance

#### Technical Implementation

**Architecture**:
- **Modular Profiling**: Separate profiling contexts for different aspects
- **High-Resolution Timing**: Uses `clock_gettime(CLOCK_MONOTONIC)` for nanosecond precision
- **Memory Monitoring**: Integration with `getrusage()` for system-level memory tracking
- **Thread Safety**: Atomic operations for statistics in multi-threaded environments

**Key Data Structures**:
```c
typedef struct {
    uint64_t start_time_ns;
    uint64_t end_time_ns;
    uint64_t duration_ns;
    size_t memory_before;
    size_t memory_after;
    size_t memory_peak;
    uint64_t allocations;
    uint64_t deallocations;
    bool completed;
} PhaseMetrics;

typedef struct {
    const char *function_name;
    const char *file_name;
    int line_number;
    uint64_t call_count;
    uint64_t total_time_ns;
    uint64_t min_time_ns;
    uint64_t max_time_ns;
    double avg_time_ns;
} HotPath;
```

**Performance Characteristics**:
- **Overhead**: < 5% performance impact on compilation
- **Precision**: Nanosecond-level timing accuracy
- **Memory Tracking**: Real-time with configurable sampling
- **Scalability**: Handles large compilation units efficiently

#### Integration with Existing Infrastructure

**Benchmark Framework Integration**:
- Extends existing `src/performance/benchmark.h` infrastructure
- Leverages established performance measurement patterns
- Compatible with existing performance testing workflows

**Compiler Integration**:
- Hooks into lexer creation and destruction
- Monitors parser AST generation phases
- Tracks semantic analysis timing
- Measures code generation performance

---

## Build System Integration

### Makefile Integration

Both Phase 2 tools are fully integrated into the build system through `tools/Makefile.tools`:

```makefile
# Phase 2 Tools
TEST_GENERATOR := $(BIN_DIR)/test-generator$(EXE_EXT)
PERFORMANCE_PROFILER := $(BIN_DIR)/performance-profiler$(EXE_EXT)

# Build targets
$(TEST_GENERATOR): $(TEST_GENERATOR_OBJECTS) $(TOOLS_COMMON_LIB) $(ASTHRA_RUNTIME_LIB) $(COMPILER_OBJECTS)
	@echo "Linking Test Generator..."
	$(CC) $(LDFLAGS) -o $@ $^ $(LDLIBS)

$(PERFORMANCE_PROFILER): $(PERFORMANCE_PROFILER_OBJECTS) $(TOOLS_COMMON_LIB) $(ASTHRA_RUNTIME_LIB) $(COMPILER_OBJECTS)
	@echo "Linking Performance Profiler..."
	$(CC) $(LDFLAGS) -o $@ $^ $(LDLIBS)
```

### Build Commands

```bash
# Build all tools (includes Phase 2)
make tools

# Build specific Phase 2 tools
make bin/test-generator
make bin/performance-profiler

# Clean Phase 2 tools
make clean-tools

# Get help for all tools
make help-tools
```

### Dependencies

Both tools depend on:
- **Common Library**: `libasthra_tools_common.a` for CLI framework
- **Runtime Library**: `libasthra_runtime.a` for core functionality
- **Compiler Objects**: Core compiler components for integration

---

## Development Guidelines

### Code Quality Standards

**C17 Standards Compliance**:
- Use of `_Static_assert` for compile-time validation
- Atomic operations for thread-safe statistics
- Designated initializers for structure initialization
- Modern feature detection and fallback patterns

**Memory Management**:
- Proper allocation and deallocation patterns
- Error path cleanup to prevent memory leaks
- Use of stack allocation where appropriate
- Integration with sanitizer tools for validation

**Error Handling**:
- Consistent use of `ToolResult` return types
- Comprehensive error message reporting
- Graceful degradation for non-critical failures
- Proper resource cleanup in error conditions

### Performance Considerations

**Optimization Strategies**:
- Minimize memory allocations in hot paths
- Use of atomic operations for thread-safe counters
- Efficient string handling and formatting
- Lazy evaluation for expensive operations

**Scalability**:
- Support for large input files and test suites
- Configurable limits to prevent resource exhaustion
- Streaming approaches for large data sets
- Memory-efficient data structures

### Testing and Validation

**Unit Testing**:
- Each tool includes comprehensive test coverage
- Integration tests with existing compiler infrastructure
- Cross-platform validation on supported architectures
- Performance regression testing

**Quality Assurance**:
- Static analysis with existing tools
- Memory safety validation with sanitizers
- Code review and documentation standards
- Continuous integration compatibility

---

## Troubleshooting

### Common Issues

**Build Errors**:
```bash
# If tools fail to build, ensure dependencies are built
make clean && make runtime && make tools

# Check for missing headers or libraries
make tools VERBOSE=1
```

**Runtime Issues**:
```bash
# For test generator issues with grammar files
./bin/test-generator --grammar grammar.txt --no-validate

# For profiler memory tracking issues
./bin/performance-profiler input.asthra --no-memory
```

**Performance Issues**:
```bash
# Reduce profiling overhead
./bin/performance-profiler input.asthra --mode compilation --interval 10

# Limit hot path tracking
./bin/performance-profiler input.asthra --max-paths 10
```

### Debug Information

**Verbose Output**:
Both tools support verbose operation for debugging:
```bash
./bin/test-generator --help     # Show all options
./bin/performance-profiler --help  # Show all options
```

**Statistics Reporting**:
Tools provide atomic statistics for monitoring:
- Test generation: tests created, templates processed, files written
- Performance profiling: profiles completed, phases measured, memory samples

---

## Future Enhancements

### Planned Improvements

**Test Generator**:
- Grammar-aware test generation improvements
- Property-based testing integration
- Coverage-guided test generation
- Integration with fuzzing frameworks

**Performance Profiler**:
- Real-time profiling dashboard
- Comparative analysis between runs
- Integration with external profiling tools
- Performance regression detection

### Extension Points

**Plugin Architecture**:
- Custom test template support
- External profiling tool integration
- Report format extensibility
- Custom analysis algorithms

**Integration Opportunities**:
- IDE integration for real-time feedback
- CI/CD pipeline integration
- Automated performance regression detection
- Integration with code coverage tools

---

This documentation provides comprehensive guidance for using and extending the Phase 2 development tools. For additional support or to report issues, please refer to the project's issue tracking system or development team.